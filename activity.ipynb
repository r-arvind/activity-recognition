{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"climbing\",\"walking\"]\n",
    "LABELS = {\n",
    "    \"climbing\" : 1,\n",
    "    \"walking\" : 2,\n",
    "}\n",
    "SENSORS = [\"Accelerometer\",\"Gyroscope\"]\n",
    "WINDOW_LENGTH = 100\n",
    "dataset_path = \"dataset_new/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for sensors in SENSORS:\n",
    "    data[sensors] = []\n",
    "for vals in TASKS:\n",
    "    sub_dirs = [x for x in os.walk(dataset_path + vals)]\n",
    "    datapoints = sub_dirs[0][1]\n",
    "    for pts in datapoints:\n",
    "        for sensors in SENSORS:\n",
    "            file_path = dataset_path + vals + \"/\" + pts + \"/\" +sensors + \".csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Label\"] = LABELS[vals]\n",
    "            data[sensors].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = data[\"Accelerometer\"]\n",
    "gyro = data[\"Gyroscope\"]\n",
    "combine = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8776, 6) (9005, 6)\n",
      "(1808, 6) (1860, 6)\n",
      "(4907, 6) (5040, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "for i in range(len(acc)):\n",
    "    length = min(acc[i].shape[0],gyro[i].shape[0])\n",
    "    length = length - length%100\n",
    "    acc[i] = acc[i][:length]\n",
    "    gyro[i] = gyro[i][:length]\n",
    "    acc[i] = acc[i][N:-N]\n",
    "    gyro[i] = gyro[i][N:-N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8600, 6) (8600, 6)\n",
      "(1700, 6) (1700, 6)\n",
      "(4800, 6) (4800, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)\n",
    "    try:\n",
    "        acc[i].drop(acc[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "        gyro[i].drop(gyro[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    gyro[i] = gyro[i].reset_index(drop=True)\n",
    "    acc[i] = acc[i].reset_index(drop=True)\n",
    "    acc[i].columns = [\"ACCX\",\"ACCY\",\"ACCZ\",\"OUTPUT\"]\n",
    "    gyro[i].columns = [\"GYROX\",\"GYROY\",\"GYROZ\",\"OUTPUT\"]\n",
    "    if(acc[i]['OUTPUT'].equals(gyro[i][\"OUTPUT\"])):\n",
    "        acc[i].drop(acc[i][[\"OUTPUT\"]],axis=1,inplace=True)\n",
    "        df = pd.concat([acc[i], gyro[i]],axis=1)\n",
    "        combine.append(df)\n",
    "    else:\n",
    "        print(\"Error in merging tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8600, 7)\n",
      "(1700, 7)\n",
      "(4800, 7)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(combine)):\n",
    "    print(combine[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for values in combine:\n",
    "    i=0\n",
    "    while(i<= 0.7 * values.shape[0]- WINDOW_LENGTH):\n",
    "        i = int(i)\n",
    "        temp = values[i:i+WINDOW_LENGTH]\n",
    "        temp_input = temp.drop(temp[['OUTPUT']],axis=1)\n",
    "        temp_output = temp[['OUTPUT']]\n",
    "        x_train.append(temp_input.values)\n",
    "        y_train.append(temp_output.iloc[0])\n",
    "        i = i + WINDOW_LENGTH/2\n",
    "    while(i <= values.shape[0] - WINDOW_LENGTH):\n",
    "        i = int(i)\n",
    "        temp = values[i:i+WINDOW_LENGTH]\n",
    "        temp_input = temp.drop(temp[['OUTPUT']],axis=1)\n",
    "        temp_output = temp[['OUTPUT']]\n",
    "        x_test.append(temp_input.values)\n",
    "        y_test.append(temp_output.iloc[0])\n",
    "        i = i + WINDOW_LENGTH/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train_mean = []\n",
    "x_train_std = []\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test_mean = []\n",
    "x_test_std = []\n",
    "\n",
    "for layer_one in x_train:\n",
    "    df = pd.DataFrame(layer_one)\n",
    "    df_mean = df.rolling(100).mean()\n",
    "    df_mean.dropna(inplace=True)\n",
    "    df_mean.reset_index(drop=True, inplace=True)\n",
    "    add_mean = np.array(df_mean.loc[0])\n",
    "    x_train_mean.append(add_mean)\n",
    "    \n",
    "    df_std = df.rolling(100).std()\n",
    "    df_std.dropna(inplace=True)\n",
    "    df_std.reset_index(drop=True, inplace=True)\n",
    "    add_std = np.array(df_std.loc[0])\n",
    "    x_train_std.append(add_std)\n",
    "\n",
    "for layer_one in x_test:\n",
    "    df = pd.DataFrame(layer_one)\n",
    "    df_mean = df.rolling(100).mean()\n",
    "    df_mean.dropna(inplace=True)\n",
    "    df_mean.reset_index(drop=True, inplace=True)\n",
    "    add_mean = np.array(df_mean.loc[0])\n",
    "    x_test_mean.append(add_mean)\n",
    "    \n",
    "    df_std = df.rolling(100).std()\n",
    "    df_std.dropna(inplace=True)\n",
    "    df_std.reset_index(drop=True, inplace=True)\n",
    "    add_std = np.array(df_std.loc[0])\n",
    "    x_test_std.append(add_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.310215  ,  1.17302764,  9.78272034, ...,  0.52073494,\n",
       "         0.61953981,  0.36297557],\n",
       "       [-0.92605317,  0.89971695, 10.12663574, ...,  0.53757168,\n",
       "         0.61888026,  0.33879463],\n",
       "       [-0.89474976,  1.03776627, 10.28174408, ...,  0.42617391,\n",
       "         0.54360879,  0.37191048],\n",
       "       ...,\n",
       "       [-0.4182428 ,  1.02815414,  9.98152328, ...,  0.26842086,\n",
       "         0.36528772,  0.38860891],\n",
       "       [-0.41635178,  1.2272792 ,  9.89510483, ...,  0.26747761,\n",
       "         0.32495962,  0.4057471 ],\n",
       "       [-0.29691712,  1.27813187,  9.82352984, ...,  0.24758335,\n",
       "         0.30603538,  0.3464894 ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mean_df = pd.DataFrame(x_train_mean)\n",
    "x_train_std_df = pd.DataFrame(x_train_std)\n",
    "x_train_featured_df = x_train_mean_df.join(x_train_std_df, lsuffix = 'mean', rsuffix = 'std')\n",
    "x_train_featured = np.array(x_train_featured_df)\n",
    "\n",
    "x_train_mean_df = pd.DataFrame(x_train_mean)\n",
    "x_train_std_df = pd.DataFrame(x_train_std)\n",
    "x_train_featured_df = x_train_mean_df.join(x_train_std_df, lsuffix = 'mean', rsuffix = 'std')\n",
    "x_train_featured = np.array(x_train_featured_df)\n",
    "x_train_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 12)\n",
      "(207, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_featured = np.array(x_train_featured)\n",
    "print(x_train_featured.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_featured = np.array(x_test_featured)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "clf.fit(x_train_featured, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 6 should be equal to 12, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-d5ec182269a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_featured\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    472\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    473\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 6 should be equal to 12, the number of features at training time"
     ]
    }
   ],
   "source": [
    "clf.score(x_test_featured, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
