{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"climbing\",\"jumping\",\"running\"]\n",
    "LABELS = {\n",
    "    \"climbing\" : 1,\n",
    "    \"jumping\" : 2,\n",
    "    \"running\" : 3,\n",
    "}\n",
    "SENSORS = [\"Accelerometer\",\"Gyroscope\"]\n",
    "WINDOW_LENGTH = 100\n",
    "dataset_path = \"dataset/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for sensors in SENSORS:\n",
    "    data[sensors] = []\n",
    "for vals in TASKS:\n",
    "    sub_dirs = [x for x in os.walk(dataset_path + vals)]\n",
    "    datapoints = sub_dirs[0][1]\n",
    "    for pts in datapoints:\n",
    "        for sensors in SENSORS:\n",
    "            file_path = dataset_path + vals + \"/\" + pts + \"/\" +sensors + \".csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Label\"] = LABELS[vals]\n",
    "            data[sensors].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = data[\"Accelerometer\"]\n",
    "gyro = data[\"Gyroscope\"]\n",
    "combine = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3025, 6) (3034, 6)\n",
      "(2428, 6) (2437, 6)\n",
      "(3210, 6) (3221, 6)\n",
      "(1809, 6) (1825, 6)\n",
      "(2185, 6) (2203, 6)\n",
      "(1747, 6) (1763, 6)\n",
      "(1849, 6) (1867, 6)\n",
      "(3025, 6) (3034, 6)\n",
      "(2428, 6) (2437, 6)\n",
      "(3210, 6) (3221, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "for i in range(len(acc)):\n",
    "    length = min(acc[i].shape[0],gyro[i].shape[0])\n",
    "    length = length - length%100\n",
    "    acc[i] = acc[i][:length]\n",
    "    gyro[i] = gyro[i][:length]\n",
    "    acc[i] = acc[i][N:-N]\n",
    "    gyro[i] = gyro[i][N:-N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2900, 6) (2900, 6)\n",
      "(2300, 6) (2300, 6)\n",
      "(3100, 6) (3100, 6)\n",
      "(1700, 6) (1700, 6)\n",
      "(2000, 6) (2000, 6)\n",
      "(1600, 6) (1600, 6)\n",
      "(1700, 6) (1700, 6)\n",
      "(2900, 6) (2900, 6)\n",
      "(2300, 6) (2300, 6)\n",
      "(3100, 6) (3100, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)\n",
    "    try:\n",
    "        acc[i].drop(acc[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "        gyro[i].drop(gyro[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    gyro[i] = gyro[i].reset_index(drop=True)\n",
    "    acc[i] = acc[i].reset_index(drop=True)\n",
    "    acc[i].columns = [\"ACCX\",\"ACCY\",\"ACCZ\",\"OUTPUT\"]\n",
    "    gyro[i].columns = [\"GYROX\",\"GYROY\",\"GYROZ\",\"OUTPUT\"]\n",
    "    if(acc[i]['OUTPUT'].equals(gyro[i][\"OUTPUT\"])):\n",
    "        acc[i].drop(acc[i][[\"OUTPUT\"]],axis=1,inplace=True)\n",
    "        df = pd.concat([acc[i], gyro[i]],axis=1)\n",
    "        combine.append(df)\n",
    "    else:\n",
    "        print(\"Error in merging tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(combine)):\n",
    "    print(combine[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for values in combine:\n",
    "    i=0\n",
    "    while(i<= values.shape[0]- WINDOW_LENGTH):\n",
    "        i = int(i)\n",
    "        temp = values[i:i+WINDOW_LENGTH]\n",
    "        temp_input = temp.drop(temp[['OUTPUT']],axis=1)\n",
    "        temp_output = temp[['OUTPUT']]\n",
    "        x_train.append(temp_input.values)\n",
    "        y_train.append(temp_output.iloc[0])\n",
    "        i = i + WINDOW_LENGTH/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train):\n",
    "    \n",
    "    n_time_steps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 70, 16\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
