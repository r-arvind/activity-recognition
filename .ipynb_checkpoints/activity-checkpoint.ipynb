{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\"climbing\",\"walking\"]\n",
    "LABELS = {\n",
    "    \"climbing\" : 1,\n",
    "    \"walking\" : 2,\n",
    "}\n",
    "SENSORS = [\"Accelerometer\",\"Gyroscope\"]\n",
    "WINDOW_LENGTH = 100\n",
    "dataset_path = \"dataset_new/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for sensors in SENSORS:\n",
    "    data[sensors] = []\n",
    "for vals in TASKS:\n",
    "    sub_dirs = [x for x in os.walk(dataset_path + vals)]\n",
    "    datapoints = sub_dirs[0][1]\n",
    "    for pts in datapoints:\n",
    "        for sensors in SENSORS:\n",
    "            file_path = dataset_path + vals + \"/\" + pts + \"/\" +sensors + \".csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Label\"] = LABELS[vals]\n",
    "            data[sensors].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = data[\"Accelerometer\"]\n",
    "gyro = data[\"Gyroscope\"]\n",
    "combine = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8776, 6) (9005, 6)\n",
      "(1808, 6) (1860, 6)\n",
      "(4907, 6) (5040, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "for i in range(len(acc)):\n",
    "    length = min(acc[i].shape[0],gyro[i].shape[0])\n",
    "    length = length - length%100\n",
    "    acc[i] = acc[i][:length]\n",
    "    gyro[i] = gyro[i][:length]\n",
    "    acc[i] = acc[i][N:-N]\n",
    "    gyro[i] = gyro[i][N:-N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8600, 6) (8600, 6)\n",
      "(1700, 6) (1700, 6)\n",
      "(4800, 6) (4800, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(acc)):\n",
    "    print(acc[i].shape,gyro[i].shape)\n",
    "    try:\n",
    "        acc[i].drop(acc[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "        gyro[i].drop(gyro[i][[\"Timestamp\",\"Milliseconds\"]],inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    gyro[i] = gyro[i].reset_index(drop=True)\n",
    "    acc[i] = acc[i].reset_index(drop=True)\n",
    "    acc[i].columns = [\"ACCX\",\"ACCY\",\"ACCZ\",\"OUTPUT\"]\n",
    "    gyro[i].columns = [\"GYROX\",\"GYROY\",\"GYROZ\",\"OUTPUT\"]\n",
    "    if(acc[i]['OUTPUT'].equals(gyro[i][\"OUTPUT\"])):\n",
    "        acc[i].drop(acc[i][[\"OUTPUT\"]],axis=1,inplace=True)\n",
    "        df = pd.concat([acc[i], gyro[i]],axis=1)\n",
    "        combine.append(df)\n",
    "    else:\n",
    "        print(\"Error in merging tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8600, 7)\n",
      "(1700, 7)\n",
      "(4800, 7)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(combine)):\n",
    "    print(combine[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for values in combine:\n",
    "    i=0\n",
    "    while(i<= 0.7 * values.shape[0]- WINDOW_LENGTH):\n",
    "        i = int(i)\n",
    "        temp = values[i:i+WINDOW_LENGTH]\n",
    "        temp_input = temp.drop(temp[['OUTPUT']],axis=1)\n",
    "        temp_output = temp[['OUTPUT']]\n",
    "        x_train.append(temp_input.values)\n",
    "        y_train.append(temp_output.iloc[0])\n",
    "        i = i + WINDOW_LENGTH/2\n",
    "    while(i <= values.shape[0] - WINDOW_LENGTH):\n",
    "        i = int(i)\n",
    "        temp = values[i:i+WINDOW_LENGTH]\n",
    "        temp_input = temp.drop(temp[['OUTPUT']],axis=1)\n",
    "        temp_output = temp[['OUTPUT']]\n",
    "        x_test.append(temp_input.values)\n",
    "        y_test.append(temp_output.iloc[0])\n",
    "        i = i + WINDOW_LENGTH/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train_mean = []\n",
    "x_train_std = []\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test_mean = []\n",
    "x_train_std = []\n",
    "\n",
    "for layer_one in x_train:\n",
    "    df = pd.DataFrame(layer_one)\n",
    "    df_mean = df.rolling(100).mean()\n",
    "    df_mean.dropna(inplace=True)\n",
    "    df_mean.reset_index(drop=True, inplace=True)\n",
    "    layer_one = np.array(df_mean.loc[0])\n",
    "    x_train_mean.append(layer_one)\n",
    "    \n",
    "    df_std = df.rolling(100).std()\n",
    "    df_std.dropna(inplace=True)\n",
    "    df_std.reset_index(drop=True, inplace=True)\n",
    "    add_std = np.array(df_std.loc[0])\n",
    "    x_train_std.append(add_std)\n",
    "\n",
    "for layer_one in x_test:\n",
    "    df = pd.DataFrame(layer_one)\n",
    "    df_mean = df.rolling(100).mean()\n",
    "    df_mean.dropna(inplace=True)\n",
    "    df_mean.reset_index(drop=True, inplace=True)\n",
    "    layer_one = np.array(df_mean.loc[0])\n",
    "    x_test_fmean.append(layer_one)\n",
    "    \n",
    "    df_std = df.rolling(100).std()\n",
    "    df_std.dropna(inplace=True)\n",
    "    df_std.reset_index(drop=True, inplace=True)\n",
    "    add_std = np.array(df_std.loc[0])\n",
    "    x_test_std.append(add_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 6)\n",
      "(207, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_featured = np.array(x_train_featured)\n",
    "print(x_train_featured.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_featured = np.array(x_test_featured)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "clf.fit(x_train_featured, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test_featured, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
